{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Speech Processing Labs: SIGNALS 1: Digital Speech Signals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Press shift-enter to run this first! or else press the Run button when running on a notebook server\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import cmath\n",
    "from math import floor\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML, display, Audio\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from numpy.fft import fft\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Digital Signals\n",
    "\n",
    "This is the lab corresponding to [module 3: Digital Speech Signals](https://speech.zone/courses/speech-processing/module-3-digital-speech-signals/) of the Speech Processing course.  \n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "* Understand how spectrograms relate to the Discrete Fourier Transform\n",
    "* Understand how DFT output is affected by design choices, e.g., input window size, sampling rate, windowing type\n",
    "* Understand how how digital signals can be combined through superposition\n",
    "* Understand how spectral leakage can affect spectrograms\n",
    "* Understand how aliasing can affect digital sound recordings\n",
    "* See how digital signals can be can be visualised using a range of plot types\n",
    "\n",
    "## Background\n",
    "\n",
    "* Speech Zone Module 3 videos: up to and including [Frequency Domain](https://speech.zone/courses/speech-processing/module-3-digital-speech-signals/)\n",
    "* Reading: R. Waytree (2019) Phonetics: a practical perspective, Chapters 6 and 7\n",
    "\n",
    "\n",
    "## A Note on coding\n",
    "\n",
    "The code below and throughout these notebooks is for generating visualisations, to show some concrete steps for doing this sort of analysis, and to allow you to alter parameters and see what the effect is.  But for this course, you don't have to understand every line of code unless you really want to. It's fine just to run the code and look at the output. \n",
    "\n",
    "Extension: If you have some python experience, you can try coding up some of the cells below yourself!   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting waveforms and spectrograms in python\n",
    "\n",
    "You've seen a spectrogram in Praat, but you can also do this in python! This might be helpful for you later on when writing reports. \n",
    "\n",
    "In this notebook, we'll use the general purpose python package [matplotlib](https://matplotlib.org) to make plots.  To handle audio data we'll use the [librosa](https://librosa.org/doc/latest/index.html) package. Matplotlib is pre-installed in the [Edina Noteable](https://noteable.edina.ac.uk/resources/) standard notebook, but librosa isn't.  We can install it now using the commanding the next cell:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import Librosa\n",
    "\n",
    "The following code cell will install the librosa package into your current python environment \n",
    "\n",
    "Breaking it down: \n",
    "The `!` at the beginning of the line tells jupyter notebook to run the command that follows as if it's on the unix shell (i.e., on the command line).  [`pip`](https://pypi.org/project/pip/) is a command line program that can install python packages (i.e., code collections) for you.  So, the command `pip install librosa` installs the package librosa for us.  If it's already installed it'll give you several \"requirement already satisfied\" messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now to use `librosa` in the notebook we need to import it (as we did for various packages up the top). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a sound file with librosa\n",
    "\n",
    "Now let's [load a sound file](https://librosa.org/doc/latest/generated/librosa.load.html) that's already in our repo and make a html audio widget to play it in the notebook. \n",
    "It's a short recording of a violin playing a single note.  \n",
    "\n",
    "Note, in the python cells below lines starting with `#` are comments: They are explanations and ignored when running the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the variable 'filename' to the path of the file\n",
    "## You can read the file path as directions for how to get to the file: \n",
    "## i.e., \"..\" = up a directory, then into the 'sounds' directory, then the actual filename\n",
    "filename = \"../sounds/violin_A4_05_forte_arco-normal.wav\"\n",
    "\n",
    "## Load the waveform amplitudes y from the file and also get the sampling rate sr\n",
    "y, sr = librosa.load(filename)\n",
    "\n",
    "## Make an html audio widget so you can listen to the audio from this notebook\n",
    "Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've loaded the mp3 file and returned two outputs, which are stored in the variables `y` and `sr`:\n",
    "* `y`: The waveform (i.e. amplitude sequence)\n",
    "* `sr`: The sampling rate of the recording - this will have the value 22050 Hz. \n",
    "\n",
    "**Task:** Try changing the sample rate in the following while keeping `y` the same.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the value of the variable sr\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make an audio widget that plays y but change the sample rate to 16000\n",
    "## Uncomment the following line by deleting the \"#\" at the beginning and change XXXX to the \n",
    "## sample rate you want\n",
    "# Audio(data=y, rate=XXX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happened when you changed the sampling rate? What about the sound changed? Why did this happen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the audio (and some python warmups)\n",
    "Let's look at `y` first.  You can inspect the contents of a variable by inputting it as the last line in a code cell and running the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inspect the y variable that \"holds\" our waveform \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a formatted version of an array of numbers (i.e., a list of numbers, but more efficiently represented for our purposes using the package [numpy](https://numpy.org) - a python package that, for our purposes, makes dealing with vectors and matrices easier). These numbers are the amplitude samples that make up the audio recording ordered in time.  \n",
    "\n",
    "We can access elements of this array by their index, where we start the index at 0.  So: `y[2]` is the 3rd sample in this array, `y[10]` is the 11th samples in the array, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a number that looks something like `-2.3283064e-10` as the output of the previous cell (since these are very small values there may be some differences in what you actually see - if the sound plays fine, don't worry!).  This is the amplitude value for the 11th sample in scientific notation: the `e-10` is intepreted as `10^{-10}`, so the overall expression is $-2.3283064 \\times 10^{-10}$, which is a very small number!  If we round this to 9 decimal places, we'll see python just prints out `-0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(y[10],9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can check what sort of array this is and the number of samples in our waveform `y` by checking the 'shape' of the array. We can do this with numpy `shape` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inspect y.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the output `(31104,`) which means that it's a 1 dimensional array of 31104 numbers. The following shows how you can set another variable `n_samples` to be the number of number of elements in `y`, and then use that variable to print out a print statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set n_samples to the first (0th) value of y.shape.  In a matrix this would be the number of rows\n",
    "n_samples = y.shape[0]\n",
    "\n",
    "## print out n_samples\n",
    "print(f\"The number of samples in y is {n_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `f\"...\"` in the print statement tells python to substitute the bits between `{` and `}` with the value of the variable named there.  So in the code above we get value of `n_samples` (31104) in the output of the cell. \n",
    "\n",
    "\n",
    "**Task:** Try writing a print statement to see what the sampling rate `sr` is in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a line here to print out the sampling rate (you can copy the previous print statement as a template) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the sampling rate is 22050 samples per second (since we're talking about frequency of sampling, people often just use Hertz as the unit for sampling rate).\n",
    "\n",
    "We can do basic arithmetic in notebooks using the following symbols\n",
    "* `+`: addition\n",
    "* `-`: subtraction/negative\n",
    "* `*`: multiplication\n",
    "* `/`: division\n",
    "* `**`: exponentiation ('to the power of')\n",
    "\n",
    "For example: running the following cell with the expression `((2**2)*4 + 5)/7` should give you the answer `3`\n",
    "(if you're not sure why - ask!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((2**2)*4 + 5)/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** the sampling rate is the number of samples per second (evenly spaced!).  So what is the sampling period? i.e., how long is there between each sample?  \n",
    "\n",
    "**Task:** Calculate the sample period given the sample rate `sr` we retrieved earlier and store it in the variable `sample_period`.  \n",
    "\n",
    "_These are just some tasks to get you used to python notebooks.  If you've never done any coding before and are stuck, ask for help!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a statement to calculate the sample period  as 1/sr\n",
    "## i.e., sample_period = ...\n",
    "\n",
    "## print out the sample period: change XXXXX\n",
    "print(f\"The sample period is XXXX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Calculate the total duration of the wavefile based on the sample period `sample_period` and the number of samples in the file `n_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the duration of the waveform: fill in XXX below\n",
    "\n",
    "print(f\"The duration of y is XXX seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the waveform\n",
    "Now let's make a visualisation of the waveform as a time vs amplitude plot. Remember that our array `y` only included the amplitude values ordered in time. So, we need to figure out what the actual time values are based on the sampling period, which we worked out above from the sampling rate `sr`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide 1 second by the number of samples per second to get the sampling period\n",
    "# we use \":.10f\" to format the sample_period to 10 decimal places.\n",
    "sample_period = 1/sr\n",
    "print(f\"The time between samples is  {sample_period:.10f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky for us, librosa figures out sample times for us when we use the function `waveshow`.  This just plots the times vs the amplitudes stored in `y`, but it has some waveform specifics that make what's happening a bit clearer (and prettier?) than the default matplotlib plot function (which we'll use later).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a matplotlib plot - yes, matplotlib syntax is unintuitive! But it's the most \n",
    "## widely used python plotting package out there, so worth knowing a bit about. \n",
    "## try changing the numbers in setting figsize to see what that does\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "\n",
    "## set some parameters about the plot:\n",
    "## xlim: the range of the x-axis\n",
    "## ylim: the range of the y-axis\n",
    "## title: The title of the plot\n",
    "ax.set(xlim=[0.0, 1.0], title='Sample view', ylim=[-0.2, 0.2])\n",
    "\n",
    "## Make the actual time vs amplitude plot\n",
    "librosa.display.waveshow(y, sr=sr, ax=ax, color='red', label='waveform')\n",
    "\n",
    "## include the automatically generated legend, though this is not very informative at the moment! \n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** change the values for `xlim` and `ylim` to zoom into the waveform until you can see some actual pitch periods. What is the F0 of this waveform? (You can calculate it the same way as for the Praat labs, count the number of cycles for a given time interval to find out the time of one cycle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the spectrogram \n",
    "\n",
    "Now let's look at a spectrogram.  To generate a spectrogram we apply the DFT to the sequence of frames (i.e. DFT input windows) from the waveform.\n",
    "\n",
    "We do this with the [librosa function stft](https://librosa.org/doc/latest/generated/librosa.stft.html#librosa.stft) (short-time fourier transform). To get the magnitude spectrum, we take absolute value of the DFT output.\n",
    "\n",
    "**Note:** The frequency-colour map that librosa produces is different to praat.  Here dark colours mean frequences have low magnitudes, lighter colours mean frequencies have higher magnitudes  (basically the opposite of Praat!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply the DFT over frames through the waveform\n",
    "y_stft = librosa.stft(y)\n",
    "\n",
    "## Get the magnitude spectrum by take the absolute value of the DFT output at each frame\n",
    "mags = np.abs(y_stft)\n",
    "\n",
    "## Setup a plot\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "\n",
    "## plot the spectogram, showing the y_axis (frequencies) on a linear scale. \n",
    "librosa.display.specshow(librosa.amplitude_to_db(mags, ref=np.max), y_axis='linear', x_axis='time', ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see a colored spectrogram with a fairly clear and stable harmonic structure.  But how do we know what the window size was? \n",
    "\n",
    "To find this out we need to check the [librosa manual page description of the stft function](https://librosa.org/doc/latest/generated/librosa.stft.html#librosa.stft), specifically the definition of the `n_fft` parameter: \n",
    "<blockquote>\n",
    "The length of the windowed signal after padding with zeros. The number of rows in the STFT matrix D is (1 + n_fft/2). <b>The default value, n_fft=2048 samples</b>, corresponds to a physical duration of 93 milliseconds at a sample rate of 22050 Hz, i.e. the default sample rate in librosa. This value is well adapted for music signals. However, in speech processing, the recommended value is 512, corresponding to 23 milliseconds at a sample rate of 22050 Hz. In any case, we recommend setting n_fft to a power of two for optimizing the speed of the fast Fourier transform (FFT) algorithm.\n",
    "    \n",
    "</blockquote>\n",
    "\n",
    "So, if we don't specify anything, the default size of the input to the DFT is 2048 samples, which is equivalent to 93 milliseconds, when the sampling rate is 22050 Hz (**task:** verify this window size for yourself).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the DFT input widow size\n",
    "Ok, let's look at what happens when we change `n_fft` to the recommended 512 samples for speech processing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## get the magnitude spectrums using windows of 512*(1/sr) seconds \n",
    "N=512\n",
    "filename = \"../sounds/violin_A4_05_forte_arco-normal.wav\"\n",
    "y, sr = librosa.load(filename)\n",
    "mags = np.abs(librosa.stft(y, n_fft=N))\n",
    "\n",
    "## plot the spectrogram\n",
    "## Because we're not using the default n_fft anymore, we also have to tell the specshow function what \n",
    "## the hop_length is (i.e. what the shift in time between each window).  \n",
    "## This is set to n_fft/4 by default in stft \n",
    "## (the '//' means return and integer value for the division, to ensure we get a whole number as the hop_length). \n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mags, ref=np.max), sr=sr, n_fft=N, hop_length=N//4,\n",
    "                         y_axis='linear', x_axis='s', ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What changed in the spectrogram comparing the orignal with `n_fft=2048` and then with `n_fft=512`?\n",
    "What are the differences in terms of the visible frequency structure (e.g. formants) and the temporal structure? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the bigger the DFT input window the more frequency resolution, but this is a tradeoff with the temporal resolution: we see more detail on changes in time with smaller DFT input windows. \n",
    "\n",
    "For this specific violin example, the window size change how how well we can see changes in the energy in corresponding to the vibrato (i.e. wobbling of the notes). If we reduce the window size further the individual frequency information will start to blur. Try it out for yourself by changing `N` below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set the number of samples to include in each input window as N - try N=128 as an example\n",
    "N=512\n",
    "\n",
    "## Calculate the magnitude spectrum\n",
    "mags = np.abs(librosa.stft(y, n_fft=N))\n",
    "\n",
    "## plot the spectrogram\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mags, ref=np.max), y_axis='linear', x_axis='time', ax=ax, n_fft=N, hop_length=N//4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying the pitch \n",
    "\n",
    "Now let's look at another violin recording of a note at a different pitch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## open the file violin_A3_15_forte_arco-normal.mp3 from the sounds directory\n",
    "filename = \"../sounds/violin_A3_15_forte_arco-normal.mp3\"\n",
    "\n",
    "## read in the wave information as y2 \n",
    "y2, sr2 = librosa.load(filename)\n",
    "\n",
    "## make an audio widget to play it\n",
    "Audio(data=y2, rate=sr2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the spectrograms for the two recordings side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the mag spectrums for y2\n",
    "N=512\n",
    "mags1 = np.abs(librosa.stft(y, n_fft=N))\n",
    "mags2 = np.abs(librosa.stft(y2, n_fft=N))\n",
    "\n",
    "## This time let's make two plots side by side, we can refer to them with the variables ax1 and ax2\n",
    "fig, (ax1, ax2)  = plt.subplots(nrows=1, ncols=2, figsize=(16,4))\n",
    "\n",
    "## Plot the spectrogram of the previous recording in ax1 (left)\n",
    "ax1.set(title=\"Violin A4\")\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mags1, ref=np.max), sr=sr, n_fft=N, hop_length=N//4,\n",
    "                         y_axis='linear', x_axis='time', ax=ax1)\n",
    "\n",
    "## Plot the spectrogram of the other recording in ax2 (right)\n",
    "ax2.set(title=\"Violin A3\")\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mags2, ref=np.max),sr=sr, n_fft=N, hop_length=N//4,\n",
    "                         y_axis='linear', x_axis='time', ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** \n",
    "What's the main difference in the spectrograms? How is this related to the audible difference in pitch between the two samples? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Extracting F0 contours\n",
    "\n",
    "_This part on extracting F0 in librosa is a bit of a side-quest.  You can skip it if you're pressed for time_\n",
    "\n",
    "We can extract Fundamental frequency (F0) values for the two recordings to verify the perceptual relationship between F0 and perceived pitch.  Here we'll use librosa's [F0 extractor which uses the Yin method](https://librosa.org/doc/latest/generated/librosa.pyin.html#librosa.pyin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimate the fundamental frequency over sliding windows of 512 samples\n",
    "## We set the minimum potential frequency to 50 Hz, and maximum to 600 Hz.  \n",
    "## Proper setting of min and max usually necessary to get good F0 estimates for speech research\n",
    "## though obviously other instruments can go a lot higher or lower. \n",
    "N=512\n",
    "f0_a4, _, _  = librosa.pyin(y=y, sr=sr, fmin=50, fmax=600, frame_length=N)\n",
    "\n",
    "## Get the times for the f0 samples based on the sample rate\n",
    "times_a4 = librosa.times_like(f0_a4, sr=sr, hop_length=N//4)\n",
    "\n",
    "f0_a3, _ , _  = librosa.pyin(y=y2, sr=sr, fmin=50, fmax=600, frame_length=N)\n",
    "times_a3 = librosa.times_like(f0_a3, sr=sr, hop_length=N//4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what this got us for the \"A4\" recording (`y`, `f0_a4`), versus the \"A3\" recording (`y2`, `f0_a3`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_a3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the extracted F0 (i.e. pitch) values for the A4 recording are generally around 441 Hz, while the F0 for the A3 recording is around 220 Hz. If you're a musician you will have noticed that they are 1 octave in difference (by definition \"A4\" should be 440Hz). \n",
    "\n",
    "Let's plot the F0 values: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "ax.plot(times_a4, f0_a4, linewidth=4, color='green', marker=\".\", label='f0: A4')\n",
    "ax.plot(times_a3, f0_a3, linewidth=4, color='magenta', marker=\"x\", label='f0: A3')\n",
    "ax.set(title=\"time vs Fundamental Frequency (F0)\", ylabel=\"Frequency (Hz)\", xlabel=\"Time (s)\")\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get what we expect, two slightly wobbly F0 contours at 441Hz and 220Hz. Since they're just holding the one note, this is not very exciting, but we'd expect to see a lot more movement in F0 in human speech! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining sounds with different fundamental frequencies\n",
    "\n",
    "So far, all the stuff we have done we can also easily do with Praat.  One thing it's much easier to do in python is manipulate the waveform directly.  It's just an array of numbers!  \n",
    "\n",
    "We can make a new sound by adding the waveform arrays together time wise. It's very easy to add arrays together in python (with numpy!).  The arrays just have to be the same length.  Since our violin recordings aren't quite the same size, let's just that the first 25000 samples (i.e. `(1/sr)*25000 = ?` seconds).  We can change the relative amplitude of each recording by multiplying the amplitude values by a scaling factor (`1` for both in the following, but you can try changing this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the overall duration of 25000 samples at sampling rate sr (should be 22050 Hz)\n",
    "print(f\"25000 samples with a sampling rate of {sr} Hz is {(25000/sr)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y and y2 together samplewise: \n",
    "# i.e. the nth samples of y and y2 are added together to make the first sample of the \n",
    "# new combined combined waveform: y_combo[n] = y[n] + y2[n]\n",
    "\n",
    "y_combo = 1*y[0:25000]+ 1*y2[0:25000]\n",
    "Audio(data=y_combo, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** what will the fundamental frequency of the combined signal be? What happens if you make the `y` (the A4~440Hz signal) louder? How does the spectrogram change when you do this? \n",
    "\n",
    "**Task:** Change the multipliers for `y` and `y2` above and then use the code below to see how the F0 contour and spectrogram change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the number of input samples to the F0 tracker and the DFT to 512\n",
    "N=512\n",
    "\n",
    "## Get the F0 for y_combo.  You'll see here this function also returns\n",
    "## some info about voicing that we'll continue to ignore here! \n",
    "\n",
    "f0_combo, voicing, voicing_probability = librosa.pyin(y=y_combo, sr=sr, fmin=50, fmax=600, frame_length=N)\n",
    "times_combo = librosa.times_like(f0_combo, sr=sr, hop_length=N//4)\n",
    "\n",
    "## Get the magnitude spectrums\n",
    "mags_combo = np.abs(librosa.stft(y_combo, n_fft=N))\n",
    "\n",
    "## Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "\n",
    "## Plot the spectrogram\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mags_combo, ref=np.max), sr=sr, hop_length=N//4,\n",
    "                         y_axis='linear', x_axis='time', ax=ax)\n",
    "\n",
    "## Add the F0 contour to the same plot (ax)\n",
    "ax.plot(times_combo, f0_combo, linewidth=4, color='green',  label='f0')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Superposition and DFT Analysis Frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectrograms show us how we can use the DFT to analyses the frequency components of a sound waves. This builds on the fact that we create sounds by adding together other sounds.  This addition of waves is often called _superposition_, and is applicable to all sorts of waves (not just sound).\n",
    "\n",
    "The DFT specifically decomposes waves into [sinusoids](https://mathworld.wolfram.com/Sinusoid.html), i.e. sine (or cosine) waves of varying amplitude, frequency and phase. The frequencies of the sinusoids represented by the DFT output depend on the number of input samples the DFT is given and the sampling rate. \n",
    "\n",
    "For an input window containing $N$ samples, recorded at a sampling frequency (aka sampling rate) of $f_s$, the $k$th DFT output is:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    The <b>frequency</b> associated with DFT[k] is: \n",
    "    $kf_{min}$ = $kf_s/N$ Hz\n",
    "</div>\n",
    "\n",
    "We refer to the frequencies associated with DFT outputs as **analysis frequencies** for a specific DFT setup.  The set of sinusoids with these analysis frequencies forms an **orthogonal basis** that we can use to reconstruct sounds based on a spectrum. The orthogonal basis part means that if we calculate the similarity (~correlation) between any of the sinusoids in the basis, the result will be 0.  \n",
    "\n",
    "**Question:** The lowest analysis frequency is $f_{min} = f_s/N$.  How many cycles would the sinusoid with frequency $f_{min}$ complete in the time corresponding to $N$ samples (i.e. the length of the input window in seconds). _Hint: calculate the period of $f_{min}$, this will give you the time it takes to complete 1 cycle_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some sinusoids, alone and together\n",
    "Let's load and examine some different sine waves as examples, as well as a wave with a sinusoidal shape but increasing frequency in time.\n",
    "\n",
    "**Warning:** This sounds might be very loud over headphones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## file paths to some sine waves of different frequencies as well as \n",
    "## a wave with a sinusoidal shape but increasing frequency in time (it'll make sense when you listen to it!)\n",
    "sine100 = \"../sounds/sine_100Hz.wav\"\n",
    "sine200 = \"../sounds/sine_200Hz.wav\"\n",
    "sine300 = \"../sounds/sine_300Hz.wav\"\n",
    "sweep = \"../sounds/sweep.wav\"\n",
    "\n",
    "## Read them into different arrays with librosa\n",
    "\n",
    "## Note: sr is getting overwritten each time we call load because we keep storing it\n",
    "## in the same variable \"sr\".  We don't care hear because we know that they are infact\n",
    "## all the same sampling rate, but this is something you might need to look out for \n",
    "## when dealing with other data.  If sine100 had a different sampling rate to sweep then\n",
    "## you could get in trouble just using the last updated value of 'sr'\n",
    "\n",
    "y_100, sr = librosa.load(sine100)\n",
    "y_200, sr = librosa.load(sine200)\n",
    "y_300, sr = librosa.load(sine300)\n",
    "y_sweep, sr = librosa.load(sweep)\n",
    "\n",
    "## Make audio widgets for each of them \n",
    "## We use the 'display' function here to make sure that they all get rendered\n",
    "## If you don't do this, the notebook will only show the last one\n",
    "\n",
    "print(\"Sine wave of 100 Hz\")\n",
    "display(Audio(data=y_100, rate=sr)) # This one is a little hard to hear (for me at least!) but it is there\n",
    "\n",
    "print(\"Sine wave of 200 Hz\")\n",
    "display(Audio(data=y_200, rate=sr))\n",
    "\n",
    "print(\"Sine wave of 300 Hz\")\n",
    "display(Audio(data=y_300, rate=sr))\n",
    "\n",
    "print(\"A frequency sweep\")\n",
    "display(Audio(data=y_sweep, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the the different sinusoids and verify the frequency differences.  \n",
    "\n",
    "**Matplotlib note:** The following shows how you can make multiple subplots with the same x-axis so you can easily see the frequency differences.  Here we've set the plot to have 4 rows and 1 column. This means there's multiple axes we can use here captured with the variable `axs`.  We an reference each of these by index (0,1,2,3).  \n",
    "\n",
    "We plot each of the waveforms into a separate plot, but make sure they all share the same x-axis setting by setting `sharex=True` when calling the function `subplots`. This means that if you change the `xlim` range for `axs[0]` then it will change the bit of the waveform shown for all of the plots. \n",
    "\n",
    "Note, we're just using the matplotlib `plot` function here rather than the fancier one from librosa.  This means we need to figure out what the actual timestamps should be for each of the samples ourselves.  We can work this out by making an array representing all the sample indices (0,1,...,the number of samples in `y_200` in this case) and then multiplying them all by the sampling period.  \n",
    "\n",
    "We can conveniently do this using the numpy function arange.  You should be able to see what this function does by looking at the output of the following cell (`np.arange(10)`)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## determine the number of samples and the sampling period\n",
    "n_samples = len(y_200)\n",
    "sampling_period = 1/sr\n",
    "\n",
    "## Create an array of sample indices\n",
    "sample_indices = np.arange(0,n_samples)\n",
    "\n",
    "## Get the actual timestamps by multiplying with the sampling_period\n",
    "ts = sample_indices * sampling_period\n",
    "\n",
    "## Set up the 4x1 plot\n",
    "fig, axs = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(16,8))\n",
    "\n",
    "## Plot the individual sine waves\n",
    "axs[0].plot(ts, y_100, linewidth=1, color='green', label='waveform')\n",
    "axs[1].plot(ts, y_200, linewidth=1, color='green', label='waveform')\n",
    "axs[2].plot(ts, y_300, linewidth=1, color='green', label='waveform')\n",
    "axs[3].plot(ts, y_sweep, linewidth=1, color='green', label='waveform')\n",
    "\n",
    "## Set the x-axis limits to 0 and 0.1 - try changing this! \n",
    "axs[0].set(xlim=[0,0.1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the x-axis range set to (0,0.1) you should be able to see that there are 10 peaks for the 100 Hz sine wave, 20 for the 200 Hz, and 30 for 300 Hz.  For the 'sweep' sound you should see that the peaks get closer together in time, which we perceive as an increase in pitch over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A compound wave\n",
    "\n",
    "Now let's add the 100 Hz, 200 Hz, and 300 Hz sine waves together.  \n",
    "**Question:** What would you expect to see in the spectrogram if we input this combined sound wave? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the sine waves together\n",
    "y_sine_combo = y_200 + y_100 + y_300 \n",
    "\n",
    "## Play the combined wave\n",
    "display(Audio(data=y_sine_combo, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save time, write a function\n",
    "Copying and pasting code is tedious and makes your code more prone to errors. When you find yourself repeating tasks, you should be thinking about writing a function.  Here's one for plotting spectrograms. \n",
    "\n",
    "If you don't know anything about python or coding - don't worry! It's fine just to use the function in the following code blocks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the 'def' here says that we're defining a function.a\n",
    "## 'plot_spectrogram' is the function name.\n",
    "## the stuff in the brackets after the name are the input arguments.\n",
    "## Notice that we can set default values for various arguments, like n_fft=512).\n",
    "## This means it will use these values for these variables in the function \n",
    "## if we don't specify them when we call the function. \n",
    "\n",
    "def plot_spectrogram(y, sr, n_fft=512, window_type=\"hann\", figsize=(16,4)): \n",
    "    ## apply the STFT on y\n",
    "    mags = np.abs(librosa.stft(y, n_fft=n_fft, window=window_type))\n",
    "\n",
    "    ## create the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(mags, ref=np.max), sr=sr, hop_length=n_fft//4, \n",
    "                         y_axis='linear', x_axis='s', ax=ax)\n",
    "\n",
    "    ## return the plot\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try out the function\n",
    "N=512\n",
    "fig, ax = plot_spectrogram(y_sine_combo, sr, n_fft=N)\n",
    "\n",
    "## We can still do things to the axis 'ax' that we got as output of the function\n",
    "ax.set(title='Spectrogram: y_sine_combo')\n",
    "\n",
    "## Our combo wave is made up of sine waves with frequencies all less that 1000 Hz, \n",
    "## so let's zoom into to those frequencies:\n",
    "ax.set(ylim=[0, 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Leakage \n",
    "\n",
    "You should see that there are some bright lines around 100, 200 and 300 Hz but also on the surrounding frequencies.  How can that be if our input wave was only made of those three frequencies?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Can you explain what's happening here?  Start by calculating what the actual DFT analysis frequencies should be.\n",
    "Remember, you can do this if you know:\n",
    "* the sampling rate\n",
    "* the number of samples per frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print out the sampling rate of y_sine_combo\n",
    "\n",
    "print(f\"The sample rate of y_sine_combo  is XXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print out the lowest analysis frequency that can be captured by the DFT given the input length\n",
    "## in samples (512 in this case) and the sampling rate (sr) of the recording. \n",
    "\n",
    "print(f\"The DFT output frequencies are multiples of XXXX\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis frequencies and Leakage\n",
    "You should find that the lowest analysis frequency for a sample rate of 22050 Hz and an window size of 512 samples is 43.07 Hz. So, the analysis frequencies captured by the DFT in this case are the integer multiples of that up to the Nyquist Frequency. This means that 100Hz, 200Hz, and 300 Hz all fall between the analysis frequencies. So, their \"presence\" in the input ends up getting \"leaked\" onto (i.e. represented by) surrounding analysis frequencies.  \n",
    "\n",
    "For our specific case the closest analysis frequencies are 86.13, 215.33, 301.46, etc, but we also see positive magnitudes in the spectrum at other nearby frequencies.  \n",
    "\n",
    "How and when this happens is effected the **windowing functions** we apply to input windows (i.e. frames) before applying the DFT. We won't go into it much in this course, but suffice to say there's a reason there are [so many window functions](https://docs.scipy.org/doc/scipy/reference/signal.windows.html) that have been proposed for different tasks! \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Task:** can you find a window size (in number of samples) that will give you whole number analysis frequencies and also a decent number of samples?  \n",
    "\n",
    "Generate a sine wave that is exactly one of these analysis frequencies.\n",
    "\n",
    "Hint: here are some factors of 22050: 1, 2, 3, 5, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We get an whole integer analysis frequencies if our DFT input size is ????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we try with a combination of $N=450$ and input frequency $f=147$, since 147 Hz should be an analysis frequencies for $N=450$ and a sampling rate of 22050 Hz.\n",
    "\n",
    "We use the numpy function `linspace` below to get a specific number of samples (`sr*T`), evenly spaced between `0` and and `T`. So if T=1 second we get 22050 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a 1 second sine wave with frequency f=147 Hz\n",
    "T = 1 ## max time\n",
    "sr  = 22050 ## sampling rate\n",
    "f = 147  ## sinusoid frequency\n",
    "\n",
    "## make the time samples, we want sr*T samples evenly space from time 0 to T\n",
    "time_samples = np.linspace(0, T, int(sr*T), endpoint=False)\n",
    "\n",
    "## get the sine wave amplitudes for a frequency f for the time samples we want\n",
    "## We can use numpy's built in sin function for this\n",
    "xs = np.sin(2 * np.pi * f * time_samples)\n",
    "\n",
    "## make a plot\n",
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "ax.plot(time_samples, xs, linewidth=1, color='green', label='wav')\n",
    "ax.set(xlim=[0,0.1], xlabel=\"Time (s)\", ylabel=\"amplitude\", title=\"A 147 Hz sine wave\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's listen (147 Hz)\n",
    "display(Audio(data=xs, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of the windowing function \n",
    "\n",
    "Now, if we choose the window size such that the input sine wave frequency is one of the DFT analysis frequencies, we get less leakage: But the amount depends on the windowing function. Let's first try the default, which is the **Hann** window (a generally good all-purpose windowing function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the spectrogram with N=450 as the size of the input to the DFT (in samples) \n",
    "## and using the \"hann\" window: this tapers the edges of the window\n",
    "N=450\n",
    "fig, ax = plot_spectrogram(xs, sr=sr, n_fft=N, window_type=\"hann\")\n",
    "ax.set(title=f'Spectrogram of a f={f} Hz sine wav, windows size N={N} samples, Window type = Hann', ylim=[0, 500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! But we're still still seeing leakage! It turns out that [this a property of the Hann windowing function](https://brianmcfee.net/dstbook-site/content/ch06-dft-properties/Leakage.html): if you apply this windowing function to your input and your input is one of the analysis frequencies, it'll give you some leakage! \n",
    "\n",
    "In this case, our problem goes away if you use a rectangular or 'boxcar' window which is equivalent to no window at all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_spectrogram(xs, sr=sr, n_fft=450, window_type=\"boxcar\")\n",
    "ax.set(title=f'Spectrogram of a f={f} Hz sine wav, windows size N={N} samples, Window type = boxcar (rectangle)', ylim=[0, 500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we seem to have gotten rid of the leakage (at least away from the waveform edges). \n",
    "\n",
    "Does this mean we should just use a rectangular window? Well, no.  It turns out, for speech processing at least,  the advantages of using the Hann shaped window for reducing the amount of leakage overall is outweighed the loss of precision for the specific DFT analysis frequencies.  In general, we are more interested in getting a good estimate of the overall shape of the spectrum rather than specific single frequencies.  However, this isn't the case for all signal processing applications.\n",
    "\n",
    "Librosa allows you to use any of the [windowing functions implemented in the scipy package](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.get_window.html#scipy.signal.get_window).  Feel free to try them out to see what they do! You can actually just think of these windowing functions as a type of filter - more on this in module 4!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling and Aliasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've kept with a standard sampling rate, 22050 Hz. What happens if we want to reduce the sampling rate?  This happens a lot for applications like ASR where machine learning models are trained expecting 16kHz and sometimes even 8KHz input. \n",
    "\n",
    "What happens if we just downsample but reducing the number of samples? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive downsampling \n",
    "\n",
    "Here's a somewhat naive strategy for for downsampling: \n",
    "If I have N samples per second, and only want M samples per second, I just take every \n",
    "N/Mth one. \n",
    "For example,\n",
    "* If I have 100 samples and I only want 20, then just take every 100/20 = 5th one\n",
    "* If my sampling rate is 22050 but I only want 8000 of them per second, then I take every 22050/8000th of the original samples\n",
    "\n",
    "Let's try down sampling from our original 22050 Hz to 8000 Hz for the \"frequency sweep\" recording. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the sampling rate of the original recording, orig_sr to 22050 Hz\n",
    "orig_sr = 22050\n",
    "\n",
    "## Set the target sampling rate, target_sr to 8000 Hz\n",
    "target_sr = 8000\n",
    "\n",
    "## Let's try this out on the sweep wave\n",
    "## You can also try adding in the other sine waves to see what happens to them\n",
    "ys = y_sweep\n",
    "\n",
    "## Find the indices of the samples that we want to keep \n",
    "## This is N/M in the text above\n",
    "k = round(orig_sr/target_sr)\n",
    "\n",
    "## Make a list of multiples of k between 0 and the number of samples in y\n",
    "## These are the samples we want to keep after downsampling\n",
    "\n",
    "downsample_index = np.arange(0, len(ys), k)\n",
    "y_ds = ys[downsample_index]\n",
    "Audio(y_ds, rate=target_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something weird has happened to the sweep sound! It seems to go up in frequency and then down again, when before it just went up. This is aliasing! \n",
    "\n",
    "Let's look at the spectrogram to verify: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_spectrogram(y_ds, sr=target_sr, n_fft=512)\n",
    "ax.set(title='Spectrogram: Frequency sweep, downsampled to 8000 Hz (originally 22050 Hz)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the sweep frequencies in the spectrogram start to go down again after 4000 Hz, i.e. half the target sampling rate, the Nyquist Frequency. \n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "For N input samples, The DFT outputs represent N frequencies evenly spaced between 0 Hz and the sampling rate, but we can only actually analyze frequencies up to half the sampling rate (i.e., the Nyquist Frequency) \n",
    "</div>\n",
    "\n",
    "Let's plot the waveform for another view of what's happening. \n",
    "\n",
    "**Task:** You can change the `xlim` values to zoom in to see what is happening at different parts of the recording. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the time samples based on the original sampling rate, by creating an\n",
    "## array of sample indices from 0 to the length of ys (the number of samples in the recording)\n",
    "## Get the time stamps by multplying this array of indices by the sampling period\n",
    "\n",
    "original_time_samples = np.arange(0,len(ys)) * (1/orig_sr)\n",
    "\n",
    "## Similarly, get the time stamps based on the target sampling rate\n",
    "target_time_samples = np.arange(0,len(y_ds)) * (1/target_sr)\n",
    "\n",
    "## Plot both the original waveform and the downsampled one, linking the x-axis for both to be shared\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(16,4), sharex=True)\n",
    "axs[0].plot(original_time_samples, ys, linewidth=0.5, color='green', marker=\".\", label='original wav')\n",
    "axs[1].plot(target_time_samples, y_ds, linewidth=0.5, color='green', marker=\".\", label='downsampled wav')\n",
    "\n",
    "## Set x-axis to zoom in on a specific part of the waveform \n",
    "axs[0].set(xlim=[0.1, 0.2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that at the beginning of the waveforms, the sine waves are fairly matched even if there they are not perfectly aligned due to the very naive way we sampled and then reconstructed the time steps for the downsampled version.  \n",
    "\n",
    "Further along in time you'll see that the downsampled sinusoid starts to look abit rough, and after it hits the 4000 Hz, the wave for the downsampled version starts to look like the \"mirror\" frequency of the original wave (e.g. 4500 Hz in the original looks like 3500 Hz in the downsampled version). \n",
    "\n",
    "This is the heart of aliasing: with the lower sample rate we just can't sample fast enough to capture frequencies higher than the Nyquist frequency. Instead we get something that looks like a lower frequency than it actually should be.  \n",
    "\n",
    "This means that if we have frequencies that are higher than half the sample rate in our original sounds when recording, they will still be captured but at the incorrect frequency!  If we want to avoid this we need to remove those higher frequencies before doing any other processing (using filtering).  This is what a \"real\" resampling algorithm would do.\n",
    "\n",
    "The following cell applies [librosa's resampling function](https://librosa.org/doc/latest/generated/librosa.resample.html#librosa-resample) to our sine wave combo plus the sweep.  You'll hear that the lower frequency sine waves are preserved, but the sweep just disappears after it hits 4000 Hz.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sr=8000\n",
    "y_resample = librosa.resample(y_sine_combo +y_sweep, orig_sr=orig_sr, target_sr=target_sr)\n",
    "display(Audio(data=y_resample, rate=target_sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_spectrogram(y_resample, sr=target_sr, n_fft=512)\n",
    "ax.set(title='Spectrogram: sine waves and sweek resampled by librosa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Shifts\n",
    "\n",
    "So far, we've just been focusing on the magnitude spectrum and sine waves. However, if you look at the raw DFT output (before taking the absolute value) you'll find that it also includes phase information. \n",
    "\n",
    "Your default sine wave has the form $sin(2\\pi f t)$ where $f$ is the frequency of the sine wave and $t$ is the time we want to get the amplitude for.  \n",
    "\n",
    "A phase shift tells us to shift the starting point of the sinusoid by some amount, usually expressed in terms of an angle, $\\theta$.  This looks like:  $sin(2\\pi f t + \\theta)$. \n",
    "\n",
    "It's easier to see this visually, so let's generate some sine waves with and without phase shifts.  First, let's make a function to generate sine waves of different frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a function to generate sinusoids, potentially with phase shifts \n",
    "def gen_sine_wave_with_phase_shift(frequency, phase_angle=0, sample_rate=22050, duration=1.0):\n",
    "    ## calculate times for samples given sample rate and specified duration\n",
    "    time_samples = np.linspace(0, duration, int(sample_rate*duration), endpoint=False)\n",
    "\n",
    "    ## Generate amplitudes for a sinusoid of the specific frequency and phase shift for those time steps\n",
    "    amplitudes = np.sin(2 * np.pi * frequency * time_samples + phase_angle)\n",
    "\n",
    "    ## Return both the time steps and the amplitudes\n",
    "    return time_samples, amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate and plot some sine waves using the function above:\n",
    "\n",
    "**Question:** If we generate sine waves of the same frequency, but different phase shift, will they sound different? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying the phase of one of the sinusoids changes the look of the wavform but not the how it sounds\n",
    "\n",
    "sr = 22050 ## sampling rate\n",
    "\n",
    "## generate amplitudes for a sine wave of frequency 300Hz with no phase shfit\n",
    "f1=300\n",
    "theta1=0\n",
    "ts, x1 = gen_sine_wave_with_phase_shift(frequency=f1, phase_angle = theta1, sample_rate=sr)\n",
    "\n",
    "## generate amplitudes for a sine wave of frequency 300Hz with a pi/2 = 90 degree phase shift\n",
    "f2=300\n",
    "theta2=np.pi/2\n",
    "ts, x2 = gen_sine_wave_with_phase_shift(frequency=f2, phase_angle = theta2, sample_rate=sr)\n",
    "\n",
    "## Plot x1 and x2 sinusoids as well as x1+x2, so they all share x-axis parameters\n",
    "fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(16,8), sharex=True)\n",
    "axs[0].plot(ts, x1, linewidth=1, color='green', label='wav')\n",
    "axs[1].plot(ts, x2, linewidth=1, color='blue', label='shifted')\n",
    "axs[2].plot(ts, x1+x2, linewidth=1, color='magenta', marker=\".\", label='summed')\n",
    "\n",
    "## Set x-axix parameters - change xlim to zoom into different parts of the waveform\n",
    "axs[0].set(xlim=[0,0.05])\n",
    "axs[0].set(title=\"Sine wave: 300 Hz, no phase shift\")\n",
    "axs[1].set(title=\"Sine wave: 300 Hz, 90 degree phase shift\")\n",
    "axs[2].set(title=\"Sine wave: 300 Hz, no shift and 90 degree phase shift waves summed\")\n",
    "\n",
    "print(f\"x1: {f1} Hz, {theta1} radians phase shift\") \n",
    "display(Audio(x1, rate=22050, normalize=False))\n",
    "\n",
    "print(f\"x2: {f2} Hz, {theta2:.2f} radians phase shift\") \n",
    "display(Audio(x2, rate=22050, normalize=False))\n",
    "\n",
    "print(f\"x1 + x2\") \n",
    "display(Audio(x1+x2, rate=22050, normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the sine wave with no phase shift starts at time $t=0$ with an amplitude of zero that then regularly rises up and down.  \n",
    "\n",
    "The phase shifted sine wave (middle figure) instead starts at 1, i.e. as if we had shifted 1st sine wave to the left.  This 90 degree phase shifted sine wave is actually equivalent to a cosine wave.  \n",
    "\n",
    "Actually, technically the DFT deals with cosine waves not sine waves but this only affects the phase spectrum, not the magnitude spectrum so we often use the two interchangeably (it does matter if you're trying to interpret the phase spectrum though!).  \n",
    "\n",
    "If we add the two sine waves together (bottom figure), we see that we still get a sine wave of the same frequency but it has a different phase shift again (something between the two we started with).  However, if you listen to the audio for the three sine waves they sound pretty much the same. This perceptual invariance is the primary reason we focus on the magnitude spectrum in speech processing.  \n",
    "\n",
    "**Tasks:** try changing the phase shift in the code above to see the relationship between the period of the sine waves and the phase angle.  \n",
    "* It's easiest to do this in radians where: $2\\pi$ radians equals 360 degrees (so $\\pi/2$ radians = 90 degrees).\n",
    "* What happens when the phase shift is 360 degrees? How about 720 degrees ($4\\pi$ radians).\n",
    "* What happens if you give it a negative phase angle?  \n",
    "\n",
    "**Question:** What happens to the combined wave if you change the second sine wave to be very close but not quite the same as the first sine wave (e.g. 300 vs 310 Hz)? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sine waves and complex sinusoids\n",
    "\n",
    "It can be easier to understand why we talk about phase angles if we look a bit more at what a sine wave actually represents. It's the vertical projection of a rotation of a point around the a circle centred a (0,0).  \n",
    "\n",
    "This is visualised in the following animation, where the **amplitude** of the sine wave matches the **height** of the point as it goes around the circle (the blue dot). \n",
    "\n",
    "![Complex sinusoid to cosine and sine wave gif](../fig/phasor.gif)\n",
    "\n",
    "You can see that one complete period of the sine wave corresponds to a 360 degrees around the circle: ending up back where we started at (1,0).  A phase shift of 90 degrees is the same as starting the \"clock hand\" on the circle after rotating it 90 degrees from the starting point. \n",
    "\n",
    "A cosine wave is the horizontal projection of the same circle (not shown here). You can determine these vertical and horizontal projection using good old trigonometry (though we won't ask you to do this in class!).\n",
    "\n",
    "Increasing the frequency of the sine wave is equivalent to going around the circle faster - we make more cycles in the same amount of time.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension: What is the DFT really? \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "The details in this section about the use of the complex numbers in the DFT are not examinable, but are really just a starting point for further understanding, as well as the details you'd need to actually implement this yourself (which you can do!). \n",
    "</div>\n",
    "\n",
    "The description of the DFT in this course has, thus far, been quite high level and mostly focused on the magnitude spectrum.  We don't really need you to get into all the details of the DFT but it's worth knowing a bit about what the DFT actually outputs, and how it's possible to get both phase and magnitude information from the DFT.  In fact, if you use an off-the-shelf DFT function, like the `fft` function from `numpy`, or the `stft` function from `librosa`, you will get phase and magnitude information out in the first instance, whether you want it or not.  This is why we had to apply the `np.abs` absolute value function before plotting the spectrogram above. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DFT: Waveforms in, complex numbers out\n",
    "\n",
    "The thing that we have been skirting around about the DFT is that it's out is actually a set of complex numbers.  That is, numbers of the form $a+ib$ where $i=\\sqrt{-1}$.  In fact, this is what the 2-D plane on the left of the animation represents: the complex plane.  Each complex number is represented by a 'real' part $a$ and and 'imaginary' part $b$.  \n",
    "\n",
    "When we do the DFT we're actually calculating the similarity between our input waveforms and sinusoids in the complex plane. Because of this, the outputs of the DFT end up being a sequence of complex numbers.  This is why if you look in Jurafsky and Martin, or other textbooks you'll see the DFT defined as: \n",
    "\n",
    "* **Input:**  $N$ amplitude samples over time \n",
    "    * $x[n]$, for $n=0..N-1$ (i.e. a time series of $N$ samples)\n",
    "    \n",
    "    \n",
    "* **Output:** the dot product (i.e., the similiarity) between the input and $N$ complex sinusoids with different frequencies\n",
    "    * DFT[k] $= Me^{-j\\phi}$, i.e. a complex number (in polar form) with **magnitude** $M$ and **phase** angle $\\phi$\n",
    "    * The $N$ DFT outputs represent $N$ equally space frequencies between 0 and the sampling rate.\n",
    "\n",
    "     \n",
    "Where the outputs are calculated using the following formula for $k=0,...N-1$. \n",
    "$$ \n",
    "\\begin{align}\n",
    "DFT[k] &= \\sum_{n=0}^{N-1} x[n] e^{-i \\frac{2\\pi n}{N} k} \\\\\n",
    "\\text{ or equivalently, } DFT[k] &= \\sum_{n=0}^{N-1} x[n]\\big[\\cos(\\frac{2\\pi n}{N} k) - i \\sin(\\frac{2\\pi n}{N} k) \\big] \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "That is the output is, N complex numbers from which we extract magnitude and phases of specific complex sinusoids.  The key here is that terms of the form $M e^{-i\\theta}$ are a nifty way to express complex numbers, and from which we can easily read of magnitude ($M$) and phase angle ($\\theta$).   \n",
    "\n",
    "For the Speech Processing course we don't expect you to get into the details of this or calculate the DFT yourself.  But it is important to know that when you apply the `stft` of `fft` functions in python packages, you'll get complex numbers as output.  To get the magnitude spectrum you'll need to take absolute values of those DFT outputs.  \n",
    "\n",
    "It's all actually very neat and if you want to learn more there are some other notebooks here that go through the DFT in more detail. But you can see this for yourself by trying out the [fft](https://numpy.org/doc/stable/reference/generated/numpy.fft.fft.html#numpy.fft.fft) function from the numpy package (which is what the librosa spectrogram generator uses by default). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import numpy's fft function\n",
    "from numpy.fft import fft\n",
    "\n",
    "## Set the sampling rate to 8000 Hz\n",
    "sr = 8000\n",
    "\n",
    "## Create a sine wave of frequency 300 Hz and no phase shift, sampled at sr Hz\n",
    "ts, xs = gen_sine_wave_with_phase_shift(frequency=300, phase_angle = 0, sample_rate=sr)\n",
    "\n",
    "## Set the size of the DFT input window to N=80 samples\n",
    "N = 80\n",
    "\n",
    "## Get a window consisting of the first 0 to N samples from our waveform\n",
    "current_window = xs[0:N]\n",
    "\n",
    "## Apply the fft (the \"fast\" version of the DFT) to the window of N samples\n",
    "dft_outputs = fft(current_window)\n",
    "\n",
    "## print the output shape of the dft output, check the number of output values is the same as N\n",
    "print(f\"The DFT output shape is {dft_outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inspect the dft outputs\n",
    "dft_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! That's not exactly easy to read! It can be easier to see what's happening with these complex numbers if we plot the outputs in the complex plane, so let's try that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up a square plot (4,4)\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "## Set the axes limits, title, and axis labels\n",
    "ax.set(xlim=[-100,100], ylim=[-100,100], title=\"DFT outputs in the complex plane\", xlabel=\"real component\", ylabel=\"imaginary component\")\n",
    "\n",
    "## Plot horizontal and vertical lines through (0,0) just for reference\n",
    "ax.plot([-200,200], [0,0], color='grey', zorder=0)\n",
    "ax.plot([0,0],[-200,200], color='grey', zorder=0)\n",
    "\n",
    "## Plot our dft outs with the real component on as the x-axis value, and the the imaginary (i) component on the y-axis\n",
    "## Note python uses \"j\" to represent the imaginary number, but you'll see it as \"i\" in most maths textbooks\n",
    "\n",
    "ax.scatter(dft_outputs.real, dft_outputs.imag, zorder=10)\n",
    "\n",
    "## print out formatted versions of the DFT outputs, only if the magnitude is greater than zero\n",
    "print(\"** DFT outputs with positive magnitude**\\n\")\n",
    "\n",
    "## iterate over each dft output index k, and the output value val,\n",
    "for k, val in enumerate(dft_outputs):\n",
    "\n",
    "    ## Check if the current magnitude is greater that zero\n",
    "    ## There are computational issues with representing zeros and very small numbers here, so we'll just approximate\n",
    "    ## zero here with a very small number.\n",
    "    magnitude = np.abs(val)\n",
    "    if np.abs(val) > 0.0000000001:\n",
    "            ## get the phase angle in radians\n",
    "            angle=np.angle(val) \n",
    "            \n",
    "            ## convert it to degrees\n",
    "            angle_in_degrees= 360*angle/(2*np.pi)\n",
    "\n",
    "            ## get the analyses frequency represented by this DFT output\n",
    "            analysis_frequency = k * (sr/N)\n",
    "\n",
    "            ## Print out the dft output value in a+bi format, as well as magnitude and angle\n",
    "            print(f\"dft_outputs[{k}] = {val.real:.2f} + {val.imag:.2f}i\")\n",
    "            print(f\"\\t* magnitude={magnitude:.2f}, angle={angle:.2f} radians\")\n",
    "            print(f\"\\t* angle in degrees = {angle_in_degrees:.2f}\")\n",
    "\n",
    "            ## Print out the analysis frequency\n",
    "            print(f\"\\t* Analysis frequency = {analysis_frequency} Hz\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DFT outputs and Aliasing\n",
    "\n",
    "You should see here that we found 2 DFT outputs with non-zero magnitude that corresponding to 300 Hz and 7700 Hz sine waves. \n",
    "Since our sampling rate was 8000 Hz, we can only capture frequencies up to 4000 HZ. The 7700 Hz component is basically due to aliasing. \n",
    "\n",
    "We won't go through the details in this course, but it is worth knowing that if you look at the full DFT output spectrums (e.g. using the numpy `fft` function) you will see this sort of mirroring.  If your input has a component of $f$ Hz, you'll also positive magnitudes for $f$ and $f_s - f$, where $f_s$ is the sampling rate  (e.g., 300Hz, and 7700Hz = 8000-300Hz in the example above.). These mirrored components above the Nyquist frequencies are misleading if you just want to know what frequency components are in your input, which is why we usually discard the upper half of the DFT output.  However, they are necessary if you want to reconstruct the a waveform from the magnitude and phase spectrums (i.e., the _Inverse_ Discrete Fourier Transform).  \n",
    "\n",
    "One more thing to note here is that we see phase angle for the 300 Hz component is -90 degrees. This is because DFT phase shifts are determined relative to cosine waves (which are just sine waves shifted by 90 degrees). \n",
    "\n",
    "If you want more details on this and the mechanics of the DFT in general, you can check out the extension notebooks or [this very nice set of lecture notes by Brian McFee](https://brianmcfee.net/dstbook-site/content/ch05-fourier/intro.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Exercises\n",
    "\n",
    "\n",
    "1. We have an input of waveform made of 3 sine waves: 100 Hz, 200 Hz, 300 Hz.  The sampling rate $f_s$ is 8000 Hz and number of samples in each frame (i.e. window) is $N=80$. Let's say you put this through the DFT.  \n",
    "* Looking at the _complete_ DFT output, what analysis frequencies would the 80 DFT outputs theoretically represent?\n",
    "* Which of those 80 frequencies can we actually accurately capture? Why?\n",
    "    * Another way to think about it: of those frequencies which would we usually see plotted on a spectrogram? \n",
    "* Out of the analysis frequencies we can capture, which will show positive (i.e. non-zero) magnitudes in the magnitude given our input?\n",
    "\n",
    "2. Now, instead assume that the number of samples $N$ is 100:\n",
    "    * What are the DFT analysis frequencies now?\n",
    "    * Does using this larger input window $N$ give you better frequency resolution? How about time resolution?  \n",
    "    * Which frequencies do you expect will show positive magnitudes given that the window is take from the same input as before?  \n",
    "\n",
    "3. Assume the sampling rate of your waveform is 16000 Hz (instead of 8000 Hz), and your input window is 80 samples.\n",
    "    * What is the range of frequencies you can now capture with the DFT?\n",
    "    * What is the number of analysis frequencies?\n",
    "     \n",
    "4. Assume your sampling rate is 16000 Hz, and your input window size is 100 samples\n",
    "    * What's the length of your input window in seconds?\n",
    "    * What will the DFT show if your input a window from a waveform made up of a 320 Hz component, and a 8640 Hz component, assuming you don't do any pre-filtering of the input?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on the DFT\n",
    "\n",
    "You can find some more notebooks that go through the DFT in more detail here in the extension material here:\n",
    "\n",
    "* [Complex numbers and sinusoids](./extension/signals-1-ext-1-digital-signals-complex-numbers.ipynb)\n",
    "* [Digital Signals: Sampling sinusoids](./extension/signals-1-ext-2-sampling-sinusoids.ipynb)\n",
    "* [The Discrete Fourier Transform](./extension/signals-1-ext-3-discrete-fourier-transform-in-detail.ipynb)\n",
    "* [More on Interpreting the DFT](./extension/signals-1-ext-4-more-interpreting-the-dft.ipynb)\n",
    "\n",
    "As mentioned above, some other good resources are \n",
    "* [Digital Signals Theory by Brian McFee](https://brianmcfee.net/dstbook-site/content/ch05-fourier/intro.html)\n",
    "* [Seeing Circles, Sines and Signals by Jack Schaedler](https://jackschaedler.github.io/circles-sines-signals/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra! Plotting speech\n",
    "\n",
    "This lab has focused on relatively simple audio examples to focus on foundational aspects of digital signal processing.  But at the end of the day we want to use this to visualise and analyse speech. So, let's see if we can make a Praat-like plot here. It's completely fine to just use Praat plots for the assignments, but if you prefer using python you may find this handy for this or other courses. \n",
    "\n",
    "For this, we'll use a sample from generated by the Festival speech synthesis system.   It's the _awb_ voice saying \"Take a picture.  It'll last longer\".  If you want an extra challenge, you can hink about why this speech doesn't sound quite like actual human speech.  But first, Let's load in the TTS sample and plot a spectrogram: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the file from lab 1: speechproc_phonlab1_2.wav\n",
    "y_awb, sr = librosa.load('../../phon/phon_lab_1/audio/speechproc_phonlab1_2.wav')\n",
    "\n",
    "## Make and audio widget to play it\n",
    "display(Audio(y_awb, rate=sr))                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the spectrogram of the audio you just loaded and check it's what you expected\n",
    "fig, ax = plot_spectrogram(y_awb, sr=sr, n_fft=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Print out the sampling rate to check it's what you expect\n",
    "print(f\"The sampling rate is: {sr} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with textgrids\n",
    "We can read in textgrid information using a package like `praatio`.  But we need to install it first, alongside the package `pandas` if you don't have it already.  `pandas` basically allows to work with table style data (i.e., data frames, like in R) in a convenient way.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install praatio \n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll import the textgrid class from `praatio`.  We'll also use the `pandas` package to make some data frames (i.e., tables) to make life easier.  If you're familiar with R, you'll probably find pandas data frames to be somewhat familiar!  \n",
    "\n",
    "Then we can read in an existing textgrid file that has words annotated on a word tier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## import the textgrid class from praatio\n",
    "from praatio import textgrid\n",
    "\n",
    "## import pandas and give it a shortname \"pd\" which we can use to refer to it\n",
    "import pandas as pd\n",
    "\n",
    "## read in the textgrid using the function textgrid.openTextgrid from praatio\n",
    "tg = textgrid.openTextgrid(\"speechproc_phonlab1_2.TextGrid\", includeEmptyIntervals=True) \n",
    "\n",
    "## Get the word tier uing the getTier function\n",
    "words = tg.getTier(\"words\")\n",
    "\n",
    "## inspect the output of getTier from the previous step\n",
    "words    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the words tier entries into a dataframe\n",
    "wordsdf = pd.DataFrame(words.entries)\n",
    "\n",
    "## add a column that's the midpoint in time for each of the words\n",
    "## we'll use this for plotting later\n",
    "wordsdf.loc[:,'midpoint'] = (wordsdf.end + wordsdf.start)/2\n",
    "\n",
    "## output the table\n",
    "wordsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the default matplotlib style with a white background and no grid lines\n",
    "plt.style.use('default')\n",
    "\n",
    "## we want to be more specific with the layout here so we'll set it up in more steps\n",
    "## First start of the figure with just the overall size\n",
    "fig = plt.figure(layout=None,  figsize=(16,4))\n",
    "\n",
    "## Add the title\n",
    "fig.suptitle('A praat-like plot', horizontalalignment=\"center\", fontsize=20)\n",
    "\n",
    "## Specify the layout as a grid, with no vertical space between the subplots\n",
    "gs = fig.add_gridspec(nrows=5, ncols=1,  hspace=0.0, wspace=0.05)\n",
    "\n",
    "## Add the first subplot to span all but the last row of the grid\n",
    "ax_spec = fig.add_subplot(gs[:-1, :])\n",
    "\n",
    "## get the spectrogram info, with DFT inputs of 512 samples\n",
    "N=512\n",
    "window_type=\"hann\"\n",
    "S = np.abs(librosa.stft(y_awb, n_fft=N, window=window_type))\n",
    "\n",
    "## Plot the spectrogram in the first subplot, ax_spec\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max), sr=sr, hop_length=N//4, \n",
    "                         y_axis='linear', x_axis='s', ax=ax_spec)\n",
    "\n",
    "## Plot vertical lines at the word boundaries\n",
    "ax_spec.vlines(x=wordsdf['start'], ymin=0, ymax=10000, color=\"white\")\n",
    "\n",
    "## Add another subplot for the word tier from the text grid\n",
    "## set the x-axis to be the same as ax_spec\n",
    "ax_words = fig.add_subplot(gs[-1, :], sharex=ax_spec)\n",
    "\n",
    "## Remove y-axis ticks\n",
    "ax_words.set(yticks=[])\n",
    "\n",
    "## A vertical lines at the word boundaries\n",
    "ax_words.vlines(x=wordsdf['start'], ymin=0, ymax=1000, color=\"grey\")\n",
    "\n",
    "## For each row of our word dataframe, plot the word at midpoint time of the word interval\n",
    "for i, row in wordsdf.iterrows():\n",
    "    ax_words.text(x=row['midpoint'], y=500, s=row['label'], color=\"black\", fontsize=16, horizontalalignment=\"center\")\n",
    "\n",
    "ax_spec.set(ylim=[0,4000])\n",
    "\n",
    "## Get reid of x-axis ticks for the spectrogram subplot\n",
    "_ = plt.setp(ax_spec.get_xticklabels(), visible=False)\n",
    "#ax0.set(xticks=[])\n",
    "#ax1.set_xlim(ax0.get_xlim())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there it is! \n",
    "\n",
    "**Very optional:** try to add more elements to the plot, e.g. the waveform at the top in another subplot, or an F0 contour.  \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Warning: matplotlib formatting can very much be a rabbithole and/or time sink! It can be fun to work on visualisations but again, it is perfectly fine just to use the plotting functions in Praat!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_You can use this space to make notes!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
